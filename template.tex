%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
\usepackage{hyperref}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
\journalname{``Journal of Grid Computing"}
%
\begin{document}

\title{Baseline study of the performance of Support Vector Machine processing in the distributed computing environment of South Africa
%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
% \subtitle{Do you have a subtitle?\\ If so, write it here}

\titlerunning{Baseline study of SVM processing on SAGrid}        % if too long for running head

\author{B. Becker %        \and
        % TODO - David - add your details here.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{B. Becker \at
              Council for Scientific and Industrial Research \\
              1 Meiring Naude Road, Pretoria
              South Africa
              Tel.: +27 12 841 400 \\
              \email{bbecker@csir.co.za}
\institute{David \at NWU}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
We report on a study conducted to determine the feasibility and performance of distributed processing of language data, using Support Vector Machines methods. This represents the first large-scale use of the CODE-RADE platform developed to provide continuous delivery of research applications in a distributed environment. The study was conducted using pre-prepared sets of data and a support-vector machine library.

\keywords{grid \and svm \and continuous delivery }
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{intro}
% General use case - how are we using SVM for language? What is being studied ?
We need to compute some things about human language. One of the things we need to do is classification. This can be done with several kinds of tools - this tool, that tool, and support vector machines (SVM). One of the libraries which we could use to do this is \texttt{libsvm} \cite{Chang2011LIBSVMMachines.}.
% TODO - David please help me expand on the general background to this work.
In this study, we set ourselves several tasks to perform:

\begin{description}
  \item[\bf Training and testing models]: Train a model based on a dataset, as well as test the validation of that model.
  \item[\bf Estimate $C$ value]: The parameter $C$\footnote{For a good discussion of SVM parameters, see {\emph e.g.} \url{http://www.svms.org/parameters}} controls the tradeoff between errors in the SVM training and the margin maximisation.
  \item[\bf Predict statistics]: Predict the overall statistics of the optimisaion showing the accuracy of the classification model based on results obtained from training and testing
\end{description}
% Basic research question : is it feasible to conduct this kind of study on a distributed computing environment ?
This kind of study is in principle well-suited to a distributed computing environment, since it is possible to decouple the various computational steps from each other and implement the workflow in a massively-parallel fashion.
\subsection{Analysis workflow}
\label{subsec:analysis}
The analysis of the data followed the same workflow, for a set of languages\footnote{The languages selected for this study were South Sotho (\texttt{ss}), Afrikaans (\texttt{afr}), Zulu (\texttt{zul} and English (\texttt{eng})} and a set of datasets containing different size dictionaries of words. These dictionaries consisted of lists of between two thousand and twelve-thousand words each, in two thousand word increments. % TODO - David - is this correct ?
For each data set, some preprocessing was performed, which involved the creation of a feature vector for training and testing data sets, as well as the feature vector for each set of language-specific data.
A range of values to train the data was also created and used to test the data. This range was also used ot normalise the values of the test set
% TODO - David please correct the above, I have no idea if it makes any sense ;)

% reminder of the workflow from the script.
% for package_name in "original" #"comparing_words" "spell-check"
%	  for size in "${DATASET}" #"4K" #"2K" "4K" "8K" "10K" "12K" # -next step - seralise this.
%     for ngram in 3 #4 5
%       for lang in "ss" "afr" "zul" "eng"
%         Create n-gram tokens across all train set
%         #Sort estracted tokens with their frequency preceeding each token item
%         for lang in "ss" "afr" "zul" "eng"
%           #Create feature vector
%           #Create feature vectors used for training and testing - text_normalization
%           #Create feature vectors used for testing - text_normalization
%           #Create feature vectors for each language specific data. This will be used to estimate precision and recall per fold. - text_normalization
%         #Create a range values based on the train data and use it to on our test data. - svm-scale
%         #Apply our range values on test set - svm-scale
%         for lang in "ss" "afr" "zul" "eng"
%           # #Apply our range values on test set - svm-scale
Finally the optimisation is done based on the data generated.
% this is what grid.py does...
\subsection{}


\section{Outline and design of the study}
\label{sec:outline}
The study would be done on 6 different data sets, which would be initially staged to as many online data storage services as available. In order to take

\subsection{Infrastructure and services used in the study}
\label{subsec:InfraServices}

% services needed.
% the network...
% 1. Core Services:
% 1.1 WMS
% 1.2 Glibrary
% 2. Site services
% 2.1 Compute elements
% 2.2 Storage elements




% BibTeX users please use one of
\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{bibliography}   % name your BibTeX data base

\end{document}
% end of file template.tex
